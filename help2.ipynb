{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_predict,cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,mean_squared_error,accuracy_score,f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns; sns.set()\n",
    "import time\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVC # \"Support vector classifier\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Εισαγωγή dataset από αρχείο CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Dry_Bean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εξαγωγή πληροφοριών του dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=data.shape[0]\n",
    "n_features = data.shape[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('Class',axis=1)\n",
    "y = data[[\"Class\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y,train_size=0.8,test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = StandardScaler().fit_transform(x_train)\n",
    "#x_test = StandardScaler().fit_transform(x_test)\n",
    "\n",
    "y_train =  np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "x = np.append(x_train, x_test).reshape(13611,16)\n",
    "y = np.append(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold times for train and pred of out of the box\n",
    "train_time_base = {}\n",
    "pred_time_base = {}\n",
    "# dictionary to store all classifier without optimization preds\n",
    "predictions = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εκτέλεση MLP Out-of-the-box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.00      0.00      0.00       255\n",
      "      BOMBAY       1.00      0.99      0.99        92\n",
      "        CALI       0.53      0.98      0.69       350\n",
      "    DERMASON       0.60      1.00      0.75       735\n",
      "       HOROZ       0.97      0.68      0.80       390\n",
      "       SEKER       0.00      0.00      0.00       376\n",
      "        SIRA       0.68      0.62      0.65       525\n",
      "\n",
      "    accuracy                           0.65      2723\n",
      "   macro avg       0.54      0.61      0.55      2723\n",
      "weighted avg       0.53      0.65      0.56      2723\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier()\n",
    "start_time = time.time()\n",
    "clf.fit(x_train, y_train)\n",
    "train_time_base[\"MLP\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "preds = clf.predict(x_test)\n",
    "pred_time_base[\"MLP\"] = time.time() - start_time\n",
    "predictions[\"MLP\"] = preds\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_MLP_acc = cross_val_score(clf,x_train,y_train,cv=10,n_jobs=-1, scoring='accuracy')\n",
    "scores_MLP_f1 = cross_val_score(clf,x_train,y_train,cv=10,n_jobs=-1,scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(['accuracy','f1'],[np.mean(scores_MLP_acc),np.mean(scores_MLP_f1)])\n",
    "plt.xlabel(\"scoring method\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.title(\"10 fold CV MLP\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εκτέλεση SVM Out-of-the-box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.35      0.08      0.13       255\n",
      "      BOMBAY       1.00      1.00      1.00        92\n",
      "        CALI       0.62      0.84      0.72       350\n",
      "    DERMASON       0.78      0.87      0.82       735\n",
      "       HOROZ       0.60      0.57      0.59       390\n",
      "       SEKER       0.37      0.23      0.29       376\n",
      "        SIRA       0.58      0.74      0.65       525\n",
      "\n",
      "    accuracy                           0.64      2723\n",
      "   macro avg       0.61      0.62      0.60      2723\n",
      "weighted avg       0.61      0.64      0.61      2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SVC()\n",
    "start_time = time.time()\n",
    "model.fit(x_train, y_train)\n",
    "train_time_base[\"SVM\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "preds =model.predict(x_test)\n",
    "pred_time_base[\"SVM\"] = time.time() - start_time\n",
    "predictions[\"SVM\"] = preds\n",
    "print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_SVM_acc = cross_val_score(model,x_train,y_train,cv=10,n_jobs=-1, scoring='accuracy')\n",
    "scores_SVM_f1 = cross_val_score(model,x_train,y_train,cv=10,n_jobs=-1,scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(['accuracy','f1'],[np.mean(scores_SVM_acc),np.mean(scores_SVM_f1)])\n",
    "plt.xlabel(\"scoring method\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.title(\"10 fold CV SVM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifiers for scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = {}\n",
    "f1 = {}\n",
    "\n",
    "def metrics_info(classifier_name, preds):\n",
    "  global accuracy, f1 \n",
    "  accuracy[classifier_name] = accuracy_score(y_test, preds)\n",
    "  f1[classifier_name] = f1_score(y_test, preds, average = \"macro\")\n",
    "  # print bar plot function\n",
    "def bar_plot(classifiers, scores, title):\n",
    "  plt.figure(figsize = (10,6))\n",
    "  y_pos = np.arange(len(classifiers))\n",
    "  plt.bar(y_pos, scores, align='center', alpha = 0.9)\n",
    "  plt.xticks(y_pos, classifiers, rotation = 45)\n",
    "  plt.ylabel('Score')\n",
    "  plt.title(title)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
    "dc_constant_horoz = DummyClassifier(strategy=\"constant\", constant='horoz'.upper())\n",
    "dc_constant_sira = DummyClassifier(strategy=\"constant\", constant= 'sira'.upper())\n",
    "dc_constant_barbunya = DummyClassifier(strategy=\"constant\", constant='barbunya'.upper())\n",
    "dc_constant_seker = DummyClassifier(strategy=\"constant\", constant='seker'.upper())\n",
    "dc_constant_bombay = DummyClassifier(strategy=\"constant\",constant='bombay'.upper())\n",
    "dc_constant_cali = DummyClassifier(strategy=\"constant\",constant='cali'.upper())\n",
    "dc_constant_dermason = DummyClassifier(strategy=\"constant\",constant='dermason'.upper())\n",
    "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
    "dc_stratified = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "# with the fit method we train the classifier with the train set\n",
    "# with the predict method predictions occur based on the input data\n",
    "start_time = time.time()\n",
    "dc_uniform.fit(x_train, y_train)\n",
    "train_time_base[\"DC Uniform\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "predictions[\"DC Uniform\"] = dc_uniform.predict(x_test)\n",
    "pred_time_base[\"DC Uniform\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "dc_constant_horoz.fit(x_train, y_train)\n",
    "train_time_base[\"DC Constant horoz\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "predictions[\"DC Constant horoz\"] = dc_constant_horoz.predict(x_test)\n",
    "pred_time_base[\"DC Constant horoz\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "dc_constant_sira.fit(x_train, y_train)\n",
    "train_time_base[\"DC Constant sira\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "predictions[\"DC Constant sira\"] = dc_constant_sira.predict(x_test)\n",
    "pred_time_base[\"DC Constant sira\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "\n",
    "start_time = time.time()\n",
    "dc_constant_bombay.fit(x_train, y_train)\n",
    "train_time_base[\"DC Constant bombay\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "predictions[\"DC Constant bombay\"] = dc_constant_bombay.predict(x_test)\n",
    "pred_time_base[\"DC Constant bombay\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "\n",
    "start_time = time.time()\n",
    "dc_constant_cali.fit(x_train, y_train)\n",
    "train_time_base[\"DC Constant cali\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "predictions[\"DC Constant cali\"] = dc_constant_cali.predict(x_test)\n",
    "pred_time_base[\"DC Constant cali\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "\n",
    "start_time = time.time()\n",
    "dc_constant_dermason.fit(x_train, y_train)\n",
    "train_time_base[\"DC Constant dermason\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "predictions[\"DC Constant dermason\"] = dc_constant_dermason.predict(x_test)\n",
    "pred_time_base[\"DC Constant dermason\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "\n",
    "dc_constant_barbunya.fit(x_train, y_train)\n",
    "train_time_base[\"DC Constant barbunya\"] = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "predictions[\"DC Constant barbunya\"] = dc_constant_barbunya.predict(x_test)\n",
    "pred_time_base[\"DC Constant barbunya\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "dc_constant_seker.fit(x_train, y_train)\n",
    "train_time_base[\"DC Constant seker\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "predictions[\"DC Constant seker\"] = dc_constant_seker.predict(x_test)\n",
    "pred_time_base[\"DC Constant seker\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "dc_most_frequent.fit(x_train, y_train)\n",
    "train_time_base[\"DC Most Frequent\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "predictions[\"DC Most Frequent\"] = dc_most_frequent.predict(x_test)\n",
    "pred_time_base[\"DC Most Frequent\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "dc_stratified.fit(x_train, y_train)\n",
    "train_time_base[\"DC Stratified\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "predictions[\"DC Stratified\"] = dc_stratified.predict(x_test)\n",
    "pred_time_base[\"DC Stratified\"] = time.time() - start_time\n",
    "\n",
    "metrics_info(\"MLP\",predictions[\"MLP\"])\n",
    "metrics_info(\"SVM\",predictions[\"SVM\"])\n",
    "metrics_info(\"DC Uniform\", predictions[\"DC Uniform\"])\n",
    "metrics_info(\"DC Constant horoz\", predictions[\"DC Constant horoz\"])\n",
    "metrics_info(\"DC Constant sira\", predictions[\"DC Constant sira\"])\n",
    "metrics_info(\"DC Constant barbunya\", predictions[\"DC Constant barbunya\"])\n",
    "metrics_info(\"DC Constant seker\", predictions[\"DC Constant seker\"])\n",
    "metrics_info(\"DC Constant bombay\", predictions[\"DC Constant bombay\"])\n",
    "metrics_info(\"DC Constant cali\", predictions[\"DC Constant cali\"])\n",
    "metrics_info(\"DC Constant dermason\", predictions[\"DC Constant dermason\"])\n",
    "metrics_info(\"DC Most Frequent\", predictions[\"DC Most Frequent\"])\n",
    "metrics_info(\"DC Stratified\", predictions[\"DC Stratified\"])\n",
    "classifier_labels = list(accuracy.keys())\n",
    "classifier_accuracy = list(accuracy.values())\n",
    "classifier_f1 = list(f1.values())\n",
    "    \n",
    "data = []\n",
    "data.append(list(accuracy.values()))\n",
    "data.append(list(f1.values()))\n",
    "print(pd.DataFrame(data, index = [\"Accuracy Score\", \"F1 Score\"], columns = list(accuracy.keys())))\n",
    "\n",
    "bar_plot(classifier_labels, [i*100 for i in classifier_accuracy], \"Accuracy Score (Out of the box)\")\n",
    "bar_plot(classifier_labels, [i*100 for i in classifier_f1], \"F1 Score (Out of the box)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum = DummyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_DUM_acc = cross_val_score(dum,x_train,y_train,cv=10,n_jobs=-1, scoring='accuracy')\n",
    "scores_DUM_f1 = cross_val_score(dum,x_train,y_train,cv=10,n_jobs=-1,scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(['accuracy','f1'],[np.mean(scores_DUM_acc),np.mean(scores_DUM_f1)])\n",
    "plt.xlabel(\"scoring method\")\n",
    "plt.ylabel(\"score\")\n",
    "plt.title(\"10 fold CV DUMMY\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preproccessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = VarianceThreshold(threshold=0.00001)\n",
    "train_reduced = selector.fit_transform(x_train)\n",
    "mask = selector.get_support()\n",
    "test_reduced = np.array(x_test)[:,mask]\n",
    "print(\"Features Used = {}\".format(np.shape(test_reduced)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier()\n",
    "start_time = time.time()\n",
    "clf.fit(train_reduced, y_train)\n",
    "train_time_base[\"MLP\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "preds = clf.predict(test_reduced)\n",
    "pred_time_base[\"MLP\"] = time.time() - start_time\n",
    "predictions[\"MLP\"] = preds\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "start_time = time.time()\n",
    "model.fit(train_reduced, y_train)\n",
    "train_time_base[\"SVM\"] = time.time() - start_time\n",
    "start_time = time.time()\n",
    "preds = model.predict(test_reduced)\n",
    "pred_time_base[\"SVM\"] = time.time() - start_time\n",
    "predictions[\"SVM\"] = preds\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.95      0.92      0.93       255\n",
      "      BOMBAY       1.00      1.00      1.00        92\n",
      "        CALI       0.93      0.96      0.94       350\n",
      "    DERMASON       0.93      0.93      0.93       735\n",
      "       HOROZ       0.96      0.95      0.96       390\n",
      "       SEKER       0.95      0.97      0.96       376\n",
      "        SIRA       0.88      0.88      0.88       525\n",
      "\n",
      "    accuracy                           0.93      2723\n",
      "   macro avg       0.94      0.94      0.94      2723\n",
      "weighted avg       0.93      0.93      0.93      2723\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BARBUNYA       0.91      0.89      0.90       255\n",
      "      BOMBAY       1.00      1.00      1.00        92\n",
      "        CALI       0.93      0.93      0.93       350\n",
      "    DERMASON       0.93      0.91      0.92       735\n",
      "       HOROZ       0.96      0.94      0.95       390\n",
      "       SEKER       0.94      0.95      0.94       376\n",
      "        SIRA       0.85      0.89      0.87       525\n",
      "\n",
      "    accuracy                           0.92      2723\n",
      "   macro avg       0.93      0.93      0.93      2723\n",
      "weighted avg       0.92      0.92      0.92      2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler # φέρνουμε τον StandarScaler ως transformer που έχει .transform kai ΄όχι ως scale()\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "selector = VarianceThreshold(0.0001)\n",
    "scaler = StandardScaler()\n",
    "ros = RandomOverSampler()\n",
    "pca = PCA()\n",
    "\n",
    "pipe = Pipeline(steps = [('selector',selector),('scaler', scaler),('sampler',ros),('pca',pca),('clf',clf)], memory = 'tmp')\n",
    "timer = time.time()\n",
    "pipe.fit(x_train,y_train)\n",
    "demo_fit_time = time.time() - timer\n",
    "timer = time.time()\n",
    "pred_mlp = pipe.predict(x_test)\n",
    "demo_pred_time = time.time() - timer\n",
    "print(classification_report(y_test, pred_mlp))\n",
    "\n",
    "model = SVC()\n",
    "pipe_svm = Pipeline(steps = [('selector',selector),('scaler', scaler),('sampler',ros),('pca',pca),('clf',model)], memory = 'tmp')\n",
    "timer = time.time()\n",
    "pipe_svm.fit(x_train,y_train)\n",
    "demo_fit_time_svm = time.time() - timer\n",
    "timer = time.time()\n",
    "pred_svm = pipe_svm.predict(x_test)\n",
    "demo_pred_time_svm = time.time() - timer\n",
    "print(classification_report(y_test, pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vthreshold = list(np.arange(start = 0, stop = 0.0002, step = 0.00005))\n",
    "print(vthreshold)\n",
    "n_components = [11,12,13,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_mlp_f1 = GridSearchCV(pipe, dict(selector__threshold=vthreshold, pca__n_components=n_components), cv=10, scoring='f1_macro', n_jobs=-1)\n",
    "estimator_mlp_f1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPF = estimator_mlp_f1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_mlp_acc = GridSearchCV(pipe, dict(selector__threshold=vthreshold, pca__n_components=n_components), cv=10, scoring='accuracy', n_jobs=-1)\n",
    "estimator_mlp_acc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPA = estimator_mlp_acc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_svm_f1 = GridSearchCV(pipe_svm, dict(selector__threshold=vthreshold, pca__n_components=n_components), cv=10, scoring='f1_macro', n_jobs=-1)\n",
    "estimator_svm_f1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMF = estimator_svm_f1.best_score_\n",
    "SVMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_svm_acc = GridSearchCV(pipe_svm, dict(selector__threshold=vthreshold, pca__n_components=n_components), cv=10, scoring='accuracy', n_jobs=-1)\n",
    "estimator_svm_acc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMA = estimator_svm_acc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [MLPF*100,MLPA*100,SVMF*100,SVMA*100]\n",
    "names = [\"MLP f1\",\"MLP accuracy\",\"SVM f1\",\"SVM accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(names,scores)\n",
    "plt.show()\n",
    "for i in range(len(scores)):\n",
    "    print(\"CLASSIFIRER {} --> {}\".format(names[i],scores[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTUNA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-26 15:09:12,883]\u001b[0m A new study created in memory with name: no-name-ce11362c-d78c-4986-9024-7aa359892d89\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:09:13,414]\u001b[0m Trial 0 finished with value: 0.9144326110907087 and parameters: {'classifier': 'MLPClassifier', 'activation': 'tanh', 'solver': 'adam', 'tol': 0.01789191, 'learning_rate': 'constant'}. Best is trial 0 with value: 0.9144326110907087.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:16,474]\u001b[0m Trial 1 finished with value: 0.541681968417187 and parameters: {'classifier': 'SVC', 'C': 0.3633430864052521, 'kernel': 'poly', 'degree': 40}. Best is trial 0 with value: 0.9144326110907087.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:17,611]\u001b[0m Trial 2 finished with value: 0.7183253764230628 and parameters: {'classifier': 'SVC', 'C': 0.29266930860900064, 'kernel': 'sigmoid', 'degree': 45}. Best is trial 0 with value: 0.9144326110907087.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:19,879]\u001b[0m Trial 3 finished with value: 0.5857510099155343 and parameters: {'classifier': 'SVC', 'C': 0.8635976637350997, 'kernel': 'poly', 'degree': 19}. Best is trial 0 with value: 0.9144326110907087.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:09:20,369]\u001b[0m Trial 4 finished with value: 0.9114946749908189 and parameters: {'classifier': 'MLPClassifier', 'activation': 'logistic', 'solver': 'adam', 'tol': 0.04431181, 'learning_rate': 'constant'}. Best is trial 0 with value: 0.9144326110907087.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:21,610]\u001b[0m Trial 5 finished with value: 0.9217774513404333 and parameters: {'classifier': 'SVC', 'C': 0.18325903115065412, 'kernel': 'rbf', 'degree': 22}. Best is trial 5 with value: 0.9217774513404333.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:24,640]\u001b[0m Trial 6 finished with value: 0.5431509364671319 and parameters: {'classifier': 'SVC', 'C': 0.6037429135614484, 'kernel': 'poly', 'degree': 47}. Best is trial 5 with value: 0.9217774513404333.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:09:25,136]\u001b[0m Trial 7 finished with value: 0.9140653690782226 and parameters: {'classifier': 'MLPClassifier', 'activation': 'tanh', 'solver': 'adam', 'tol': 0.018049910000000002, 'learning_rate': 'constant'}. Best is trial 5 with value: 0.9217774513404333.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:27,742]\u001b[0m Trial 8 finished with value: 0.561145795078957 and parameters: {'classifier': 'SVC', 'C': 0.4306003678614893, 'kernel': 'poly', 'degree': 27}. Best is trial 5 with value: 0.9217774513404333.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:09:27,962]\u001b[0m Trial 9 finished with value: 0.7098788101358795 and parameters: {'classifier': 'MLPClassifier', 'activation': 'identity', 'solver': 'sgd', 'tol': 0.05216831, 'learning_rate': 'invscaling'}. Best is trial 5 with value: 0.9217774513404333.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:30,294]\u001b[0m Trial 10 finished with value: 0.910025706940874 and parameters: {'classifier': 'SVC', 'C': 0.021415497922153415, 'kernel': 'rbf', 'degree': 2}. Best is trial 5 with value: 0.9217774513404333.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:09:30,714]\u001b[0m Trial 11 finished with value: 0.9155343371281675 and parameters: {'classifier': 'MLPClassifier', 'activation': 'tanh', 'solver': 'adam', 'tol': 0.09636961, 'learning_rate': 'constant'}. Best is trial 5 with value: 0.9217774513404333.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:09:31,007]\u001b[0m Trial 12 finished with value: 0.6603011384502387 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'sgd', 'tol': 0.09787560999999999, 'learning_rate': 'invscaling'}. Best is trial 5 with value: 0.9217774513404333.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:09:31,420]\u001b[0m Trial 13 finished with value: 0.9136981270657363 and parameters: {'classifier': 'MLPClassifier', 'activation': 'tanh', 'solver': 'adam', 'tol': 0.09870410999999998, 'learning_rate': 'constant'}. Best is trial 5 with value: 0.9217774513404333.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:09:31,764]\u001b[0m Trial 14 finished with value: 0.9166360631656262 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0.07340261, 'learning_rate': 'constant'}. Best is trial 5 with value: 0.9217774513404333.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:33,437]\u001b[0m Trial 15 finished with value: 0.9151670951156813 and parameters: {'classifier': 'SVC', 'C': 0.05995983323797849, 'kernel': 'rbf', 'degree': 18}. Best is trial 5 with value: 0.9217774513404333.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:34,411]\u001b[0m Trial 16 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.6437102650254778, 'kernel': 'rbf', 'degree': 4}. Best is trial 16 with value: 0.9239809034153507.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:35,357]\u001b[0m Trial 17 finished with value: 0.9236136614028645 and parameters: {'classifier': 'SVC', 'C': 0.7269371220428666, 'kernel': 'rbf', 'degree': 2}. Best is trial 16 with value: 0.9239809034153507.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:36,305]\u001b[0m Trial 18 finished with value: 0.9236136614028645 and parameters: {'classifier': 'SVC', 'C': 0.7502945662145667, 'kernel': 'rbf', 'degree': 5}. Best is trial 16 with value: 0.9239809034153507.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:37,248]\u001b[0m Trial 19 finished with value: 0.9236136614028645 and parameters: {'classifier': 'SVC', 'C': 0.97298798364721, 'kernel': 'rbf', 'degree': 8}. Best is trial 16 with value: 0.9239809034153507.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:38,176]\u001b[0m Trial 20 finished with value: 0.6984943077488065 and parameters: {'classifier': 'SVC', 'C': 0.9308260387789045, 'kernel': 'sigmoid', 'degree': 11}. Best is trial 16 with value: 0.9239809034153507.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:39,168]\u001b[0m Trial 21 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.6738648062413831, 'kernel': 'rbf', 'degree': 1}. Best is trial 16 with value: 0.9239809034153507.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:40,149]\u001b[0m Trial 22 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.5730021547870259, 'kernel': 'rbf', 'degree': 10}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:41,125]\u001b[0m Trial 23 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.6158444978761662, 'kernel': 'rbf', 'degree': 13}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:42,115]\u001b[0m Trial 24 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.5368738043569333, 'kernel': 'rbf', 'degree': 14}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:43,111]\u001b[0m Trial 25 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.5017875700872656, 'kernel': 'rbf', 'degree': 31}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:44,122]\u001b[0m Trial 26 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.4818420371811636, 'kernel': 'rbf', 'degree': 31}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:45,147]\u001b[0m Trial 27 finished with value: 0.7065736320235035 and parameters: {'classifier': 'SVC', 'C': 0.4695419899247527, 'kernel': 'sigmoid', 'degree': 30}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:46,222]\u001b[0m Trial 28 finished with value: 0.922879177377892 and parameters: {'classifier': 'SVC', 'C': 0.34860440186861363, 'kernel': 'rbf', 'degree': 37}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:47,214]\u001b[0m Trial 29 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.5295401774405143, 'kernel': 'rbf', 'degree': 33}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:48,203]\u001b[0m Trial 30 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.5491675297363389, 'kernel': 'rbf', 'degree': 38}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:49,250]\u001b[0m Trial 31 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.4405978459094531, 'kernel': 'rbf', 'degree': 35}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:50,219]\u001b[0m Trial 32 finished with value: 0.9236136614028645 and parameters: {'classifier': 'SVC', 'C': 0.7381848036140422, 'kernel': 'rbf', 'degree': 42}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:51,212]\u001b[0m Trial 33 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.649536763857604, 'kernel': 'rbf', 'degree': 24}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:52,190]\u001b[0m Trial 34 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.5730678851169471, 'kernel': 'rbf', 'degree': 8}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:53,197]\u001b[0m Trial 35 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.5793450552911763, 'kernel': 'rbf', 'degree': 9}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:54,238]\u001b[0m Trial 36 finished with value: 0.7069408740359897 and parameters: {'classifier': 'SVC', 'C': 0.3985562977466516, 'kernel': 'sigmoid', 'degree': 28}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:55,198]\u001b[0m Trial 37 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.8275995660241791, 'kernel': 'rbf', 'degree': 50}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:56,981]\u001b[0m Trial 38 finished with value: 0.689680499449137 and parameters: {'classifier': 'SVC', 'C': 0.8217182907707994, 'kernel': 'poly', 'degree': 9}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:57,904]\u001b[0m Trial 39 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.8193105885793315, 'kernel': 'rbf', 'degree': 16}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:58,844]\u001b[0m Trial 40 finished with value: 0.6995960337862651 and parameters: {'classifier': 'SVC', 'C': 0.8457597902662093, 'kernel': 'sigmoid', 'degree': 15}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:09:59,937]\u001b[0m Trial 41 finished with value: 0.922879177377892 and parameters: {'classifier': 'SVC', 'C': 0.30344342885856457, 'kernel': 'rbf', 'degree': 50}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:00,876]\u001b[0m Trial 42 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.7918580609392873, 'kernel': 'rbf', 'degree': 40}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:01,851]\u001b[0m Trial 43 finished with value: 0.9232464193903782 and parameters: {'classifier': 'SVC', 'C': 0.6965251049233111, 'kernel': 'rbf', 'degree': 45}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:03,320]\u001b[0m Trial 44 finished with value: 0.766801322071245 and parameters: {'classifier': 'SVC', 'C': 0.9069887635773992, 'kernel': 'poly', 'degree': 7}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:10:03,549]\u001b[0m Trial 45 finished with value: 0.6573632023503488 and parameters: {'classifier': 'MLPClassifier', 'activation': 'identity', 'solver': 'sgd', 'tol': 0.0023775099999999998, 'learning_rate': 'invscaling'}. Best is trial 22 with value: 0.9243481454278369.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:04,536]\u001b[0m Trial 46 finished with value: 0.9247153874403232 and parameters: {'classifier': 'SVC', 'C': 0.5524889535377213, 'kernel': 'rbf', 'degree': 21}. Best is trial 46 with value: 0.9247153874403232.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:10:04,875]\u001b[0m Trial 47 finished with value: 0.2699228791773779 and parameters: {'classifier': 'MLPClassifier', 'activation': 'logistic', 'solver': 'sgd', 'tol': 0.05976261, 'learning_rate': 'invscaling'}. Best is trial 46 with value: 0.9247153874403232.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:05,862]\u001b[0m Trial 48 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.5357358452859617, 'kernel': 'rbf', 'degree': 20}. Best is trial 46 with value: 0.9247153874403232.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:08,169]\u001b[0m Trial 49 finished with value: 0.569225119353654 and parameters: {'classifier': 'SVC', 'C': 0.2505264164906259, 'kernel': 'poly', 'degree': 19}. Best is trial 46 with value: 0.9247153874403232.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:10:08,514]\u001b[0m Trial 50 finished with value: 0.2699228791773779 and parameters: {'classifier': 'MLPClassifier', 'activation': 'logistic', 'solver': 'sgd', 'tol': 0.07513861, 'learning_rate': 'invscaling'}. Best is trial 46 with value: 0.9247153874403232.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:09,500]\u001b[0m Trial 51 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.6071896655308008, 'kernel': 'rbf', 'degree': 23}. Best is trial 46 with value: 0.9247153874403232.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:10,501]\u001b[0m Trial 52 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.5052222203475071, 'kernel': 'rbf', 'degree': 20}. Best is trial 46 with value: 0.9247153874403232.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:11,458]\u001b[0m Trial 53 finished with value: 0.9236136614028645 and parameters: {'classifier': 'SVC', 'C': 0.7735634829996826, 'kernel': 'rbf', 'degree': 16}. Best is trial 46 with value: 0.9247153874403232.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:12,432]\u001b[0m Trial 54 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.6047786690132126, 'kernel': 'rbf', 'degree': 24}. Best is trial 46 with value: 0.9247153874403232.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:13,434]\u001b[0m Trial 55 finished with value: 0.9247153874403232 and parameters: {'classifier': 'SVC', 'C': 0.5659341639825659, 'kernel': 'rbf', 'degree': 23}. Best is trial 46 with value: 0.9247153874403232.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:14,385]\u001b[0m Trial 56 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8795797921348095, 'kernel': 'rbf', 'degree': 11}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:15,467]\u001b[0m Trial 57 finished with value: 0.9232464193903782 and parameters: {'classifier': 'SVC', 'C': 0.39556849452519804, 'kernel': 'rbf', 'degree': 26}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:16,444]\u001b[0m Trial 58 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.6119023039158965, 'kernel': 'rbf', 'degree': 24}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:10:16,734]\u001b[0m Trial 59 finished with value: 0.5776716856408373 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'sgd', 'tol': 0.03435751, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:18,644]\u001b[0m Trial 60 finished with value: 0.6929856775615131 and parameters: {'classifier': 'SVC', 'C': 0.9852556485344471, 'kernel': 'poly', 'degree': 11}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:19,642]\u001b[0m Trial 61 finished with value: 0.9247153874403232 and parameters: {'classifier': 'SVC', 'C': 0.5642135379264847, 'kernel': 'rbf', 'degree': 18}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:20,616]\u001b[0m Trial 62 finished with value: 0.9232464193903782 and parameters: {'classifier': 'SVC', 'C': 0.6931214545954818, 'kernel': 'rbf', 'degree': 22}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:21,624]\u001b[0m Trial 63 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.571558787896942, 'kernel': 'rbf', 'degree': 12}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:23,026]\u001b[0m Trial 64 finished with value: 0.9192067572530297 and parameters: {'classifier': 'SVC', 'C': 0.10550768274197797, 'kernel': 'rbf', 'degree': 12}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:23,955]\u001b[0m Trial 65 finished with value: 0.9247153874403232 and parameters: {'classifier': 'SVC', 'C': 0.8953643982646164, 'kernel': 'rbf', 'degree': 16}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:24,911]\u001b[0m Trial 66 finished with value: 0.699228791773779 and parameters: {'classifier': 'SVC', 'C': 0.9117987480506465, 'kernel': 'sigmoid', 'degree': 17}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:25,918]\u001b[0m Trial 67 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.4566585010188125, 'kernel': 'rbf', 'degree': 21}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:26,844]\u001b[0m Trial 68 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8878897755068408, 'kernel': 'rbf', 'degree': 18}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:27,788]\u001b[0m Trial 69 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.874280663027208, 'kernel': 'rbf', 'degree': 14}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:28,761]\u001b[0m Trial 70 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8775103531545975, 'kernel': 'rbf', 'degree': 18}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:29,690]\u001b[0m Trial 71 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8813204841339365, 'kernel': 'rbf', 'degree': 18}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:30,625]\u001b[0m Trial 72 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8742882410721898, 'kernel': 'rbf', 'degree': 18}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:31,552]\u001b[0m Trial 73 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.881856338514147, 'kernel': 'rbf', 'degree': 18}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:32,491]\u001b[0m Trial 74 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.9515207046161103, 'kernel': 'rbf', 'degree': 14}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:33,418]\u001b[0m Trial 75 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8791234476435356, 'kernel': 'rbf', 'degree': 18}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:34,350]\u001b[0m Trial 76 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8775104436130429, 'kernel': 'rbf', 'degree': 14}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:35,282]\u001b[0m Trial 77 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.8630029332937068, 'kernel': 'rbf', 'degree': 14}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:36,220]\u001b[0m Trial 78 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.939601649638512, 'kernel': 'rbf', 'degree': 18}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:10:36,442]\u001b[0m Trial 79 finished with value: 0.6243114212265883 and parameters: {'classifier': 'MLPClassifier', 'activation': 'identity', 'solver': 'sgd', 'tol': 0.07453451, 'learning_rate': 'invscaling'}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:37,405]\u001b[0m Trial 80 finished with value: 0.6984943077488065 and parameters: {'classifier': 'SVC', 'C': 0.9973702499824851, 'kernel': 'sigmoid', 'degree': 5}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:38,332]\u001b[0m Trial 81 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8903901741976435, 'kernel': 'rbf', 'degree': 18}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:39,260]\u001b[0m Trial 82 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8822040000758095, 'kernel': 'rbf', 'degree': 19}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:40,235]\u001b[0m Trial 83 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.7890819405589569, 'kernel': 'rbf', 'degree': 13}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:41,187]\u001b[0m Trial 84 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.8544139969274659, 'kernel': 'rbf', 'degree': 19}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:42,132]\u001b[0m Trial 85 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.9322646875445716, 'kernel': 'rbf', 'degree': 16}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:43,082]\u001b[0m Trial 86 finished with value: 0.9239809034153507 and parameters: {'classifier': 'SVC', 'C': 0.9587273498700952, 'kernel': 'rbf', 'degree': 14}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:44,020]\u001b[0m Trial 87 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.8301522390465966, 'kernel': 'rbf', 'degree': 15}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:44,956]\u001b[0m Trial 88 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.9001408305443838, 'kernel': 'rbf', 'degree': 10}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:47,524]\u001b[0m Trial 89 finished with value: 0.5699596033786265 and parameters: {'classifier': 'SVC', 'C': 0.8056257674620869, 'kernel': 'poly', 'degree': 20}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:48,478]\u001b[0m Trial 90 finished with value: 0.9236136614028645 and parameters: {'classifier': 'SVC', 'C': 0.7563422214178598, 'kernel': 'rbf', 'degree': 17}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:49,404]\u001b[0m Trial 91 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8791542246453647, 'kernel': 'rbf', 'degree': 18}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:50,355]\u001b[0m Trial 92 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.91819531250265, 'kernel': 'rbf', 'degree': 18}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:51,297]\u001b[0m Trial 93 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.8564171743830076, 'kernel': 'rbf', 'degree': 21}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:52,239]\u001b[0m Trial 94 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8776485725729481, 'kernel': 'rbf', 'degree': 17}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:53,184]\u001b[0m Trial 95 finished with value: 0.9243481454278369 and parameters: {'classifier': 'SVC', 'C': 0.8375875345367269, 'kernel': 'rbf', 'degree': 12}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:54,091]\u001b[0m Trial 96 finished with value: 0.9236136614028645 and parameters: {'classifier': 'SVC', 'C': 0.9693423420912752, 'kernel': 'rbf', 'degree': 15}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "C:\\Users\\ΒΑΣΙΛΗΣ\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\optuna\\distributions.py:668: UserWarning: The distribution is specified by [1e-08, 0.1] and step=1e-07, but the range is not divisible by `step`. It will be replaced by [1e-08, 0.09999991].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-11-26 15:10:54,594]\u001b[0m Trial 97 finished with value: 0.9181050312155711 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0.0036564099999999997, 'learning_rate': 'constant'}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:55,552]\u001b[0m Trial 98 finished with value: 0.6984943077488065 and parameters: {'classifier': 'SVC', 'C': 0.935077323923801, 'kernel': 'sigmoid', 'degree': 17}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n",
      "\u001b[32m[I 2022-11-26 15:10:56,476]\u001b[0m Trial 99 finished with value: 0.9250826294528094 and parameters: {'classifier': 'SVC', 'C': 0.8910379938851419, 'kernel': 'rbf', 'degree': 22}. Best is trial 56 with value: 0.9250826294528094.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import sklearn.datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "import sklearn.neural_network\n",
    "\n",
    "def objective(trial):\n",
    "    vr = VarianceThreshold(0.0001)\n",
    "    sc = StandardScaler()\n",
    "    #ros = RandomOverSampler()\n",
    "  \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y,train_size=0.8,test_size=0.2, random_state=0)\n",
    "    y_train =  np.ravel(y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    \n",
    "    x_train = vr.fit_transform(x_train)\n",
    "    mask = vr.get_support()\n",
    "    x_test = np.array(x_test)[:,mask]\n",
    "\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.fit_transform(x_test)\n",
    "\n",
    "    # x_train,y_train = ros.fit_resample(x_train,y_train)\n",
    "    \n",
    "\n",
    "    # x = np.append(x_train, x_test).reshape(13611,16)\n",
    "    # y = np.append(y_train, y_test)\n",
    "\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"MLPClassifier\",\n",
    "                                                               \"SVC\"])\n",
    "    if classifier_name==\"MLPClassifier\":\n",
    "\n",
    "        # Sample hyper parameters\n",
    "        activation = trial.suggest_categorical('activation', [\"identity\", \"logistic\", \"tanh\", \"relu\"])\n",
    "        solver = trial.suggest_categorical(\"solver\", \n",
    "                                              [\"sgd\", \"adam\"])\n",
    "        tol = trial.suggest_float('tol', 1e-8,1e-1, step= 1e-7)\n",
    "        learning_rate = trial.suggest_categorical('learning_rate', \n",
    "                                           [\"constant\",\"invscaling\"])\n",
    "        # Construct the model\n",
    "        clf = MLPClassifier(activation=activation,\n",
    "                               solver=solver,\n",
    "                              tol=tol,\n",
    "                               learning_rate=learning_rate\n",
    "                               )\n",
    "    elif classifier_name==\"SVC\":\n",
    "\n",
    "        # Sample hyper parameters\n",
    "        C = trial.suggest_float('C', 1e-10, 1)\n",
    "        kernel = trial.suggest_categorical('kernel',['poly','rbf','sigmoid'])\n",
    "        degree = trial.suggest_int('degree',1, 50)\n",
    "        #gamma = trial.suggest_loguniform('gamma',0.001,10000)\n",
    "\n",
    "        # Construct the model\n",
    "        # clf = SVC(C=C, kernel=kernel, degree=degree)\n",
    "        clf = SVC(C=C,kernel=kernel,degree=degree)\n",
    "    \n",
    "    # Train the model\n",
    "    clf.fit(x_train,y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    # y_pred_test = clf.predict(x_test)\n",
    "    # loss = mean_squared_error(y_test,y_pred_test)\n",
    "\n",
    "    # print(\"Train Score:\",clf.score(x_train,y_train))\n",
    "    \n",
    "    # print(\"\\n=================\")\n",
    "    return clf.score(x_test,y_test)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05bf6954723d373e19203643aa44961c2ed94b1243a950da884af6122a33ba1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
